{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n%region us-east-2\n\n#using pre-generated standard imports; will hopefully learn which are actually needed in AWS later\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nimport boto3\n\n\nfrom pyspark.sql import SparkSession, functions as F, Window, types as T\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 24aadab4-fba2-4e5c-864b-d79a2a21e07d.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 24aadab4-fba2-4e5c-864b-d79a2a21e07d.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 5.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 24aadab4-fba2-4e5c-864b-d79a2a21e07d.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous worker type: G.1X\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 24aadab4-fba2-4e5c-864b-d79a2a21e07d.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous number of workers: 5\nSetting new number of workers to: 5\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 24aadab4-fba2-4e5c-864b-d79a2a21e07d.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous region: us-east-2\nSetting new region to: us-east-2\nRegion is set to: us-east-2\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#setup environment\ntry:\n    args = getResolvedOptions(sys.argv, ['bucket_name', 'reports_prefix', 'bls_file_path', 'population_file_path'])\nexcept:\n    args = {}\n\nBUCKET_NAME = args.get('bucket_name', 'rivkasfirstawsbucket')\nREPORTS_PREFIX = args.get('reports_prefix', 'reports/')\nBLS_FILE = args.get('bls_file_path', 'bls_data/raw/pr.data.0.Current')\nPOPULATION_FILE = args.get('population_file_path', 'population_data/raw/population_data.json')\nprint(BUCKET_NAME, REPORTS_PREFIX, BLS_FILE, POPULATION_FILE)\n\n\ns3 = boto3.client('s3')\nspark = SparkSession.builder.appName(\"BLSAnalysis\").getOrCreate()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "rivkasfirstawsbucket reports/ bls_data/raw/pr.data.0.Current population_data/raw/population_data.json\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Read bls\nbls_df = spark.read.option(\"header\", True) \\\n    .option(\"sep\", \"\\t\") \\\n    .option(\"inferSchema\", True) \\\n    .csv(f\"s3://{BUCKET_NAME}/{BLS_FILE}\")\n\nbls_df = bls_df.toDF(*[c.strip() for c in bls_df.columns])\n\n#trim string columns\nstring_columns = [field.name for field in bls_df.schema.fields if isinstance(field.dataType, T.StringType)]\nprint(string_columns)\nfor col_name in string_columns:\n    bls_df = bls_df.withColumn(col_name, F.trim(F.col(col_name)))\n\nbls_df.printSchema()\nbls_df.show()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "['series_id', 'period', 'footnote_codes']\nroot\n |-- series_id: string (nullable = true)\n |-- year: integer (nullable = true)\n |-- period: string (nullable = true)\n |-- value: double (nullable = true)\n |-- footnote_codes: string (nullable = true)\n\n+-----------+----+------+-----+--------------+\n|  series_id|year|period|value|footnote_codes|\n+-----------+----+------+-----+--------------+\n|PRS30006011|1995|   Q01|  2.6|          NULL|\n|PRS30006011|1995|   Q02|  2.1|          NULL|\n|PRS30006011|1995|   Q03|  0.9|          NULL|\n|PRS30006011|1995|   Q04|  0.1|          NULL|\n|PRS30006011|1995|   Q05|  1.4|          NULL|\n|PRS30006011|1996|   Q01| -0.2|          NULL|\n|PRS30006011|1996|   Q02| -0.3|          NULL|\n|PRS30006011|1996|   Q03| -0.1|          NULL|\n|PRS30006011|1996|   Q04|  0.2|          NULL|\n|PRS30006011|1996|   Q05| -0.1|          NULL|\n|PRS30006011|1997|   Q01|  0.3|          NULL|\n|PRS30006011|1997|   Q02|  0.7|          NULL|\n|PRS30006011|1997|   Q03|  1.0|          NULL|\n|PRS30006011|1997|   Q04|  1.5|          NULL|\n|PRS30006011|1997|   Q05|  0.9|          NULL|\n|PRS30006011|1998|   Q01|  1.6|          NULL|\n|PRS30006011|1998|   Q02|  1.6|          NULL|\n|PRS30006011|1998|   Q03|  0.5|          NULL|\n|PRS30006011|1998|   Q04| -0.3|          NULL|\n|PRS30006011|1998|   Q05|  0.8|          NULL|\n+-----------+----+------+-----+--------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#aggregate bls data\n#may need to clean\nsum_per_year = bls_df.groupBy(\"series_id\", \"year\").agg(F.sum(\"value\").alias(\"yearly_sum\"))\n\n\nbest_year = sum_per_year.withColumn(\"rank\", F.row_number().over(Window.partitionBy(\"series_id\").orderBy(F.desc(\"yearly_sum\")))) \\\n                                   .filter(F.col(\"rank\") == 1) \\\n                                   .drop(\"rank\")\n\nbest_year.show()\n#todo: rework to create tables. Need to learn AWS lakehouse.\nbest_year.toPandas().to_csv(f\"s3://{BUCKET_NAME}/reports/best_year.csv\",index=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-----------------+----+------------------+\n|        series_id|year|        yearly_sum|\n+-----------------+----+------------------+\n|PRS30006011      |2022|              20.5|\n|PRS30006012      |2022|              17.1|\n|PRS30006013      |1998|           705.895|\n|PRS30006021      |2010|              17.7|\n|PRS30006022      |2010|12.399999999999999|\n|PRS30006023      |2014|503.21600000000007|\n|PRS30006031      |2022|              20.5|\n|PRS30006032      |2021|              17.1|\n|PRS30006033      |1998|           702.672|\n|PRS30006061      |2022|              37.0|\n|PRS30006062      |2021|              31.6|\n|PRS30006063      |2024|           646.748|\n|PRS30006081      |2021|              24.4|\n|PRS30006082      |2021|              24.4|\n|PRS30006083      |2021|           110.742|\n|PRS30006091      |2002|              43.3|\n|PRS30006092      |2002| 44.39999999999999|\n|PRS30006093      |2013| 514.1560000000001|\n|PRS30006101      |2020|              33.5|\n|PRS30006102      |2020|              36.2|\n+-----------------+----+------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "population_df = spark.read.option(\"multiline\", True).json(f\"s3://{BUCKET_NAME}/{POPULATION_FILE}\")\n\npopulation_df = population_df.select(F.explode(\"data\").alias(\"data\"))\npopulation_df = population_df.select(\"data.*\")\n\npopulation_df.printSchema()\npopulation_df.show()\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- Nation: string (nullable = true)\n |-- Nation ID: string (nullable = true)\n |-- Population: double (nullable = true)\n |-- Year: long (nullable = true)\n\n+-------------+---------+------------+----+\n|       Nation|Nation ID|  Population|Year|\n+-------------+---------+------------+----+\n|United States|  01000US|3.16128839E8|2013|\n|United States|  01000US|3.18857056E8|2014|\n|United States|  01000US|3.21418821E8|2015|\n|United States|  01000US|3.23127515E8|2016|\n|United States|  01000US|3.25719178E8|2017|\n|United States|  01000US|3.27167439E8|2018|\n|United States|  01000US|3.28239523E8|2019|\n|United States|  01000US|3.31893745E8|2021|\n|United States|  01000US|3.33287562E8|2022|\n|United States|  01000US|3.34914896E8|2023|\n+-------------+---------+------------+----+\n\nhuh?\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#filter population data and aggregate:\n#may need to clean\npopulation_df = population_df.filter((F.col(\"Year\") >= 2013) & (F.col(\"Year\") <= 2018))\n\npopulation_stats = population_df.agg(\n    F.mean(\"Population\").alias(\"mean_population\"),\n    F.stddev(\"Population\").alias(\"std_population\")\n)\n\npopulation_stats.show()\n\n#todo: rework to create tables. Need to learn AWS lakehouse.\npopulation_stats.toPandas().to_csv(f\"s3://{BUCKET_NAME}/reports/population_stats.csv\",index=False)",
			"metadata": {
				"trusted": true,
				"editable": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------------+-----------------+\n|mean_population|   std_population|\n+---------------+-----------------+\n|   3.22069808E8|4158441.040908092|\n+---------------+-----------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#join the datasets and filter:\ntarget_series = \"PRS30006032\"\ntarget_period = \"Q01\"\n\nreport = bls_df.filter((F.col(\"series_id\") == target_series) & (F.col(\"period\") == target_period))\\\n                .join(population_df, bls_df.year == population_df.Year, how=\"left\")\\\n                .select(bls_df[\"*\"], \"Population\")\n\n\n\nreport.show()\n\n#todo: rework to create tables. Need to learn AWS lakehouse.\nreport.toPandas().to_csv(f\"s3://{BUCKET_NAME}/reports/bls_with_population.csv\",index=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-----------+----+------+-----+--------------+------------+\n|  series_id|year|period|value|footnote_codes|  Population|\n+-----------+----+------+-----+--------------+------------+\n|PRS30006032|1995|   Q01|  0.0|          NULL|        NULL|\n|PRS30006032|1996|   Q01| -4.2|          NULL|        NULL|\n|PRS30006032|1997|   Q01|  2.8|          NULL|        NULL|\n|PRS30006032|1998|   Q01|  0.9|          NULL|        NULL|\n|PRS30006032|1999|   Q01| -4.1|          NULL|        NULL|\n|PRS30006032|2000|   Q01|  0.5|          NULL|        NULL|\n|PRS30006032|2001|   Q01| -6.3|          NULL|        NULL|\n|PRS30006032|2002|   Q01| -6.6|          NULL|        NULL|\n|PRS30006032|2003|   Q01| -5.7|          NULL|        NULL|\n|PRS30006032|2004|   Q01|  2.0|          NULL|        NULL|\n|PRS30006032|2005|   Q01| -0.5|          NULL|        NULL|\n|PRS30006032|2006|   Q01|  1.8|          NULL|        NULL|\n|PRS30006032|2007|   Q01| -0.8|          NULL|        NULL|\n|PRS30006032|2008|   Q01| -3.5|          NULL|        NULL|\n|PRS30006032|2009|   Q01|-21.0|          NULL|        NULL|\n|PRS30006032|2010|   Q01|  3.2|          NULL|        NULL|\n|PRS30006032|2011|   Q01|  1.5|          NULL|        NULL|\n|PRS30006032|2012|   Q01|  2.5|          NULL|        NULL|\n|PRS30006032|2013|   Q01|  0.5|          NULL|3.16128839E8|\n|PRS30006032|2014|   Q01| -0.1|          NULL|3.18857056E8|\n+-----------+----+------+-----+--------------+------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		}
	]
}

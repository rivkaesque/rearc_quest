{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f83a07d6-287a-475f-a3e8-8cd9e28e868d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports and params"
    },
    "editable": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "##Please note that I am working out of the files instead of the tables. this is because I believe that this is the expected pattern. The tables are purely for publication purposes.\n",
    "from pyspark.sql import functions as F, Window, types as T\n",
    "\n",
    "# Parameters with default values. \n",
    "dbutils.widgets.text('catalog', 'rearcquest', 'Catalog')\n",
    "catalog = dbutils.widgets.get('catalog') \n",
    "\n",
    "dbutils.widgets.text('sourceSchema', 'raw', 'SourceSchema')\n",
    "sourceSchema = dbutils.widgets.get('sourceSchema')\n",
    "\n",
    "dbutils.widgets.text('targetSchema', 'reports', 'SourceSchema')\n",
    "targetSchema = dbutils.widgets.get('targetSchema')\n",
    "\n",
    "\n",
    "# Volume paths\n",
    "BlsVolume = f'/Volumes/{catalog}/{sourceSchema}/bls_data/'\n",
    "PopulationVolume = f'/Volumes/{catalog}/{sourceSchema}/population/'\n",
    "\n",
    "# File paths\n",
    "BlsFile = f'{BlsVolume}pr.data.0.Current'\n",
    "PopulationFile = f'{PopulationVolume}population_data.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1930ef96-3d90-4890-a29c-61cbbfca1a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a912e90-9c3c-4210-b5d2-e3540fede30f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ensure_path(catalog=catalog,schema=targetSchema,type='schema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5afe105-6a72-4f14-8ad4-035ca82739b2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    },
    "editable": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read BLS data from Unity Catalog Volume\n",
    "blsDf = spark.read.option(\"header\", True) \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .csv(BlsFile)\n",
    "\n",
    "blsDf = blsDf.toDF(*[c.strip() for c in blsDf.columns])\n",
    "\n",
    "# Trim string columns\n",
    "stringColumns = [field.name for field in blsDf.schema.fields if isinstance(field.dataType, T.StringType)]\n",
    "\n",
    "for colName in stringColumns:\n",
    "    blsDf = blsDf.withColumn(colName, F.trim(F.col(colName)))\n",
    "\n",
    "#blsDf.printSchema()\n",
    "#blsDf.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad8dd0b-fc32-44ae-b3a3-dd7e74ed7732",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Aggregate BLS data - find best year for each series\n",
    "sumPerYear = blsDf.groupBy(\"series_id\", \"year\").agg(F.sum(\"value\").alias(\"yearly_sum\"))\n",
    "\n",
    "# Get the year with maximum sum for each series\n",
    "bestYear = sumPerYear.groupBy(\"series_id\").agg(\n",
    "    F.max_by(\"year\", \"yearly_sum\").alias(\"year\"),\n",
    "    F.max(\"yearly_sum\").alias(\"yearly_sum\")\n",
    ")\n",
    "\n",
    "#bestYear.display()\n",
    "\n",
    "# Write to Delta table in Unity Catalog\n",
    "bestYear.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(f\"{targetSchema}.best_year\")\n",
    "\n",
    "print(f\"Saved to table: {catalog}.{targetSchema}.best_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532a0725-6d56-46e6-997e-dc78a3e971dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 5"
    },
    "editable": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read population data from Unity Catalog Volume\n",
    "populationDf = spark.read.option(\"multiline\", True).json(PopulationFile)\n",
    "\n",
    "populationDf = populationDf.select(F.explode(\"data\").alias(\"data\"))\n",
    "populationDf = populationDf.select(\"data.*\")\n",
    "\n",
    "#populationDf.printSchema()\n",
    "#populationDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f22a453-cd22-42c2-822d-ed06b4077108",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 6"
    },
    "editable": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Filter population data and aggregate\n",
    "populationDf = populationDf.filter((F.col(\"Year\") >= 2013) & (F.col(\"Year\") <= 2018))\n",
    "\n",
    "populationStats = populationDf.agg(\n",
    "    F.mean(\"Population\").alias(\"mean_population\"),\n",
    "    F.stddev(\"Population\").alias(\"std_population\")\n",
    ")\n",
    "\n",
    "#populationStats.display()\n",
    "\n",
    "# Write to Delta table in Unity Catalog\n",
    "populationStats.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{targetSchema}.population_stats\")\n",
    "\n",
    "print(f\"Saved to table: {catalog}.{targetSchema}.population_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a75ff16-6931-474d-be9d-7d4095d34a9c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 7"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Join the datasets and filter\n",
    "targetSeries = \"PRS30006032\"\n",
    "targetPeriod = \"Q01\"\n",
    "\n",
    "report = blsDf.filter((F.col(\"series_id\") == targetSeries) & (F.col(\"period\") == targetPeriod)) \\\n",
    "              .join(populationDf, blsDf.year == populationDf.Year, how=\"left\") \\\n",
    "              .select(blsDf[\"*\"], \"Population\")\n",
    "\n",
    "#report.display()\n",
    "\n",
    "# Write to Delta table in Unity Catalog\n",
    "report.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{targetSchema}.bls_with_population\")\n",
    "\n",
    "print(f\"Saved to table: {catalog}.{targetSchema}.bls_with_population\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Rearc Databricks - section 3",
   "widgets": {
    "catalog": {
     "currentValue": "rearcquest",
     "nuid": "939836d0-29ea-4af4-81f4-f3c011e29213",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "rearcquest",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "rearcquest",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "sourceSchema": {
     "currentValue": "raw",
     "nuid": "e22ac795-13ee-4a4f-b9ad-52f4d26a2fc3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "raw",
      "label": "SourceSchema",
      "name": "sourceSchema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "raw",
      "label": "SourceSchema",
      "name": "sourceSchema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "targetSchema": {
     "currentValue": "reports",
     "nuid": "e66fe071-a40b-4244-ae8e-a011d354c0d0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "reports",
      "label": "SourceSchema",
      "name": "targetSchema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "reports",
      "label": "SourceSchema",
      "name": "targetSchema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

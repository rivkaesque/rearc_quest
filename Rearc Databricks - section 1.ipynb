{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b46c32d-0ba4-4729-a91b-27f558d77c7b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports, params, and variables"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "726c5e71-aef6-424a-9127-84ba9d66b55d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2"
    }
   },
   "outputs": [],
   "source": [
    "def import_file(base_url, target_folder, filename):\n",
    "    \"\"\"Download a single file and save to Databricks Volume\"\"\"\n",
    "    try:\n",
    "        file_url = base_url + filename\n",
    "        \n",
    "        \n",
    "        # NEW DATABRICKS CODE:\n",
    "        volume_path = target_folder + filename\n",
    "        \n",
    "        # Fetch file from source with User-Agent header to comply with BLS policies\n",
    "        req = urllib.request.Request(file_url, headers={'User-Agent': 'your-email@example.com'})\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            file_content = response.read()\n",
    "            last_modified = response.headers.get(\"Last-Modified\")\n",
    "        print(last_modified)\n",
    "        # Parse source modification time using datetime.strptime\n",
    "        from datetime import datetime\n",
    "        source_dt = datetime.strptime(last_modified, \"%a, %d %b %Y %H:%M:%S %Z\")\n",
    "        source_timestamp_ms = int(source_dt.timestamp() * 1000)\n",
    "        \n",
    "        # Check if file already exists in Volume with modification time >= source time\n",
    "        try:\n",
    "            existing_files = dbutils.fs.ls(target_folder)\n",
    "            # Filter files that match filename and have modification time >= source time\n",
    "            up_to_date_files = [\n",
    "                f for f in existing_files \n",
    "                if f.name == filename and f.modificationTime >= source_timestamp_ms\n",
    "            ]\n",
    "            \n",
    "            if up_to_date_files:\n",
    "                print(f\"✓ File already up-to-date: {volume_path}\")\n",
    "                return filename\n",
    "        except Exception:\n",
    "            pass  # Target folder doesn't exist or is empty\n",
    "        \n",
    "        # Write file to Volume using dbutils\n",
    "        dbutils.fs.put(volume_path, file_content.decode('latin-1'), overwrite=True)\n",
    "        print(f\"✓ Imported file: {volume_path}\")\n",
    "        \n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"✗ Failed to import file: {filename}; {str(e)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dac35933-ca9d-4e62-839d-81bab51e4236",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [],
   "source": [
    "def create_index_html_file(target_folder):\n",
    "    \"\"\"Create an index.html file in the Databricks Volume\"\"\"\n",
    "    try:\n",
    "        # OLD AWS S3 CODE (commented out):\n",
    "        # s3 = boto3.client('s3')\n",
    "        # response = s3.list_objects_v2(Bucket=bucket_name, Prefix=target_folder)\n",
    "        # keys = [obj['Key'][len(target_folder):] for obj in response.get('Contents', [])]\n",
    "        # target_files = {filename for filename in keys if filename}\n",
    "        # \n",
    "        # html_content = \"<html><body><ul>\"\n",
    "        # for filename in target_files:\n",
    "        #     html_content += f\"<li><a href='{filename}'>{filename}</a></li>\"\n",
    "        # html_content += \"</ul></body></html>\"\n",
    "        # \n",
    "        # s3.put_object(Bucket=bucket_name, Key=target_folder + 'index.html', Body=html_content, ContentType='text/html')\n",
    "        # print(f\"✓ Created index.html file\")\n",
    "        \n",
    "        # NEW DATABRICKS CODE:\n",
    "        # List files in the Volume folder\n",
    "        existing_files = dbutils.fs.ls(target_folder)\n",
    "        target_files = {f.name for f in existing_files if f.name}\n",
    "        \n",
    "        # Generate HTML content\n",
    "        html_content = \"<html><body><ul>\"\n",
    "        for filename in target_files:\n",
    "            html_content += f\"<li><a href='{filename}'>{filename}</a></li>\"\n",
    "        html_content += \"</ul></body></html>\"\n",
    "        \n",
    "        # Write index.html to Volume\n",
    "        index_path = target_folder + 'index.html'\n",
    "        dbutils.fs.put(index_path, html_content, overwrite=True)\n",
    "        print(f\"✓ Created index.html file\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"✗ Failed to create index.html file; {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0497afe-2369-44e4-8d4c-f152539d49e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get configurations\n",
    "    base_url = 'https://download.bls.gov/pub/time.series/pr/'\n",
    "    target_folder = '/Volumes/rearcquest/default/bls_data_raw/'  \n",
    "\n",
    "    # Open link and scrape source filelist\n",
    "    req = urllib.request.Request(base_url, headers={'User-Agent': 'your-email@example.com'})\n",
    "    response = urllib.request.urlopen(req)\n",
    "    html = response.read().decode('utf-8')\n",
    "\n",
    "    # Get source filelist\n",
    "    pattern = r'<a[^>]*href=\"[^\"]*\">(pr[^<]+)</a>'\n",
    "    source_files = re.findall(pattern, html, flags=re.IGNORECASE)\n",
    "    source_files = {f for f in source_files if '://' not in f and not f.endswith('/')}\n",
    "    \n",
    "    # Get target filelist from Volume\n",
    "    try:\n",
    "        existing_files = dbutils.fs.ls(target_folder)\n",
    "        target_files = {f.name for f in existing_files if f.name}\n",
    "    except Exception:\n",
    "        target_files = set()  # Target folder doesn't exist yet\n",
    "\n",
    "    files_to_delete = {f for f in target_files - source_files if f != 'index.html'}   \n",
    "\n",
    "    # Import files\n",
    "    import_errors = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(import_file, base_url, target_folder, f) \n",
    "                    for f in source_files]\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                filename = future.result()\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                import_errors.append(str(e))\n",
    "    if import_errors:\n",
    "        raise Exception(f\"✗ Failed to import files: {', '.join(import_errors)}\")\n",
    "    \n",
    "    # Delete files\n",
    "    delete_errors = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(delete_file, target_folder, f) \n",
    "                    for f in files_to_delete]\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                filename = future.result()\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                delete_errors.append(str(e))\n",
    "    if delete_errors:\n",
    "        raise Exception(f\"✗ Failed to delete files: {', '.join(delete_errors)}\")\n",
    "\n",
    "    # Create index file\n",
    "    create_index_html_file(target_folder)\n",
    "\n",
    "    print(f\"✓ Sync complete! Files are in {target_folder}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    raise Exception(f\"Error: {str(e)}\")\n",
    "    # Todo - better error handling"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Rearc Databricks - section 1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
